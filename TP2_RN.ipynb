{"nbformat":4,"nbformat_minor":2,"metadata":{"interpreter":{"hash":"457c281a83241da4648ec81cf106d34389ffd4d8ae4852b6770ac14ecedd72da"},"kernelspec":{"name":"python3","display_name":"Python 3.7.6 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"orig_nbformat":4,"colab":{"name":"TP2_RN_Male.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","source":["#Redes Neuronales 2021\n","\n","Integrantes de grupo:\n","\n","Müller, Malena\n","\n","Scala, Tobías \n","# TP2: Sesgos en el dataset de SNLI\n","\n","El trabajo practico consiste en predecir las ventas diarias para los proximos 6 meses de Rossmann, que opera en 3000 locales en 7 paises europeos. Las ventas son influenciadas por varios factores; incluyendo promociones, competencia, el periodo escolar, fechas festivas, temporada y ubicacion. \n"],"metadata":{"id":"drS7_HAXhlXM"}},{"cell_type":"markdown","source":["## Importacion de datos\n","\n","En esta primera etapa, levantamos los datos provenientes de los archivos de train, test y store, que corresponden al periodo de tiempo a los años entre el 2013 y el 2015. Luego chequeamos si faltan datos en ciertos campos de cada linea que fue levantada de los archivos."],"metadata":{"id":"6vZbiCyyl79U"}},{"cell_type":"code","execution_count":1,"source":["import pandas as pd\n","import numpy as np\n","#import datetime\n","#from isoweek import Week"],"outputs":[],"metadata":{"id":"Loz4_zOxndZj","executionInfo":{"status":"ok","timestamp":1636325781130,"user_tz":180,"elapsed":1178,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}}}},{"cell_type":"code","execution_count":null,"source":["\n","\n","trainFile = pd.read_csv('train.csv')\n","#print(trainFile.columns)\n","testFile = pd.read_csv('test.csv')\n","#print(trainFile.columns)\n","storeFile = pd.read_csv('store.csv')\n","#print(trainFile.columns)\n","\n","#Me fijo si faltan datos en TRAIN.\n","print('train[Customers]: NA = ', sum(trainFile['Customers'].isna()))\n","print('train[Open]: NA = ', sum(trainFile['Open'].isna()))\n","print('train[Promo]: NA = ', sum(trainFile['Promo'].isna()))\n","print('train[StateHoliday]: NA = ', sum(trainFile['StateHoliday'].isna()))\n","print('train[SchoolHoliday]: NA = ', sum(trainFile['SchoolHoliday'].isna()))\n","\n","#Me fijo si faltan datos en TEST.\n","# print('test[Customers]: NA = ', sum(testFile['Customers'].isna())) #No tiene Customers.\n","print('test[Open]: NA = ', sum(testFile['Open'].isna())) #11\n","print('test[Promo]: NA = ', sum(testFile['Promo'].isna()))\n","print('test[StateHoliday]: NA = ', sum(testFile['StateHoliday'].isna()))\n","print('test[SchoolHoliday]: NA = ', sum(testFile['SchoolHoliday'].isna()))\n","\n","#Me fijo si faltan datos en STORE.\n","print('store[StoreType]: NA = ', sum(storeFile['StoreType'].isna()))\n","print('store[Assortment]: NA = ', sum(storeFile['Assortment'].isna()))\n","print('store[CompetitionDistance]: NA = ', sum(storeFile['CompetitionDistance'].isna())) #3\n","print('store[Promo2]: NA = ', sum(storeFile['Promo2'].isna()))\n","\n","# print(trainFile['StateHoliday'].value_counts())\n","# print(sum(trainFile['StateHoliday'] == 0))\n","# print(sum(trainFile['StateHoliday'] == '0'))\n","\n","# trainFile['StateHoliday'] = trainFile['StateHoliday'].astype(str)\n","\n","# print(trainFile['StateHoliday'].value_counts())\n","# print(sum(trainFile['StateHoliday'] == 0))\n","# print(sum(trainFile['StateHoliday'] == '0'))\n","\n","# print(storeFile['CompetitionOpenSinceYear'].value_counts())\n","# print(len(storeFile['CompetitionOpenSinceYear']))\n","# print(storeFile['CompetitionDistance'].max())"],"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\Tobias Scala\\anaconda3\\envs\\rn\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]},{"output_type":"stream","name":"stdout","text":["train[Customers]: NA =  0\n","train[Open]: NA =  0\n","train[Promo]: NA =  0\n","train[StateHoliday]: NA =  0\n","train[SchoolHoliday]: NA =  0\n","test[Open]: NA =  11\n","test[Promo]: NA =  0\n","test[StateHoliday]: NA =  0\n","test[SchoolHoliday]: NA =  0\n","store[StoreType]: NA =  0\n","store[Assortment]: NA =  0\n","store[CompetitionDistance]: NA =  3\n","store[Promo2]: NA =  0\n"]}],"metadata":{"id":"lAhFA7_YgAHF","outputId":"9861b736-71a7-42e0-c3a3-6baa531ae5a7"}},{"cell_type":"markdown","source":["## Preprocesamiento de datos\n","\n","En cada data set levantado previamente, completamos con los datos faltantes teniendo en cuenta los siguientes criterios:\n","- En el campo \"Open\": Este campo puede tomar los valores de 1 (Abierto) y 0 (Cerrado). En caso de que no se haya indicado nada en este campo, se lo considera como cerrado (0).\n","- En el campo \"Competition Distance\": Dado que hay negocios de competencia que no existian previamente a la fecha de inicio de datos, solo hay informacion de distancia a la que se encuentra esa competencia a partir del momento en el que se establecio en su lugar geografico. Como necesitamos que haya informacion correspondiente a la distancia a la que se encuentra la competencia desde el inicio de fecha de los datos del data set, es necesario completar con informacion las fechas que no tienen dato. Si un local de competencia no existe aun, no tiene impacto en las ventas de nuestros locales y lo mismo ocurre con un local de competencia que geograficamente se encuentra muy lejos. Por eso se decidio tomar como criterio que para las fechas en las que la competencia aun no existia, la distancia sea completada con un valor muy grande de distancia (como si estuviera muy lejos). Este valor elegido es el maximo encontrado en el dataset.\n","- Tanto en el campo \"CompetitionOpenSinceYear\" como en el campo \"CompetitionOpenSinceMonth\": En caso de que no haya informacion en estos campos, se asume que la competencia ya existia para la fecha de los primeros datos del dataset, por lo que se le asigna a cada campo el dato minimo presente en el dataset. \n","\n"],"metadata":{"id":"LF-KbdYinkes"}},{"cell_type":"code","execution_count":null,"source":["#Completamos los datos en todos los archivos.\n","\n","testFile.loc[testFile['Open'].isna(), 'Open'] = 0\n","\n","storeFile.loc[storeFile['CompetitionDistance'].isna(), 'CompetitionDistance'] = storeFile['CompetitionDistance'].max()\n","storeFile.loc[storeFile['CompetitionOpenSinceYear'].isna(), 'CompetitionOpenSinceYear'] = storeFile['CompetitionOpenSinceYear'].min()\n","storeFile.loc[storeFile['CompetitionOpenSinceMonth'].isna(), 'CompetitionOpenSinceMonth'] = storeFile['CompetitionOpenSinceMonth'].min()\n","\n","# print(trainFile['Date'][0])"],"outputs":[],"metadata":{"id":"vgdikBEBgAHJ"}},{"cell_type":"markdown","source":["\n","En esta parte pasamos las fechas al formato de fechas necesario para los analisis siguientes, empleando una funcion de Pandas. Pasamos los datos numericos a int32 con la finalidad de poder interpretarlos luego como numeros. Y borramos la columna (o campo) de \"Costumers\" presente en los datos levantados de train, ya que en test no estaban estos datos y buscamos que haya consistencia entre los campos de datos que tenemos de train y de test.\n","\n"],"metadata":{"id":"1ZZudMefvsmu"}},{"cell_type":"code","execution_count":null,"source":["#Empiezamos a preprocesar los datos.\n","\n","import datetime\n","\n","trainFile['Date'] = pd.to_datetime(trainFile.Date)\n","testFile['Date'] = pd.to_datetime(testFile.Date)\n","storeFile['CompetitionOpenSinceYear'] = storeFile['CompetitionOpenSinceYear'].astype(np.int32)\n","storeFile['CompetitionOpenSinceMonth'] = storeFile['CompetitionOpenSinceMonth'].astype(np.int32)\n","storeFile['CompetitionOpenSince'] = pd.to_datetime(storeFile.apply(lambda x: datetime.datetime(x.CompetitionOpenSinceYear, x.CompetitionOpenSinceMonth, 1), axis=1))\n","\n","trainFile['CompetitionDistance'] = np.zeros(len(trainFile['Date']))\n","for i in range(len(trainFile['Date'])):\n","    if(trainFile['Date'][i] > storeFile['CompetitionOpenSince'][trainFile['Store'][i] - 1]):\n","        trainFile['CompetitionDistance'][i] = storeFile['CompetitionDistance'][trainFile['Store'][i] - 1]\n","    else:\n","        trainFile['CompetitionDistance'][i] = storeFile['CompetitionDistance'].max()\n","#trainFile['StateHoliday'] = ['0' if trainFile['StateHoliday'] == 0 else trainFile['StateHoliday']]\n","trainFile['StateHoliday'] = trainFile['StateHoliday'].astype(str)\n","trainFile['SchoolHoliday'] = trainFile.SchoolHoliday != '0' #Convertimos strings a bool (ya que es binario).\n","#trainFile['SchoolHoliday'] = trainFile['SchoolHoliday'].astype(np.int8)\n","del trainFile['Customers'] #Borramos la columna costumers ya que el test no lo tiene (?).\n","#print(trainFile.head())\n","\n","testFile['CompetitionDistance'] = np.zeros(len(testFile['Date']))\n","for i in range(len(testFile['Date'])):\n","    if(testFile['Date'][i] > storeFile['CompetitionOpenSince'][testFile['Store'][i] - 1]):\n","        testFile['CompetitionDistance'][i] = storeFile['CompetitionDistance'][testFile['Store'][i] - 1]\n","    else:\n","        testFile['CompetitionDistance'][i] = storeFile['CompetitionDistance'].max()\n","#trainFile['StateHoliday'] = ['0' if trainFile['StateHoliday'] == 0 else trainFile['StateHoliday']]\n","testFile['StateHoliday'] = testFile['StateHoliday'].astype(str)\n","testFile['SchoolHoliday'] = testFile.SchoolHoliday != '0' #Convertimos strings a bool (ya que es binario).\n","#testFile['SchoolHoliday'] = testFile['SchoolHoliday'].astype(np.int8)\n","#print(testFile.head())"],"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-209-7c7ca1c695bc>:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  trainFile['CompetitionDistance'][i] = storeFile['CompetitionDistance'][trainFile['Store'][i] - 1]\n","<ipython-input-209-7c7ca1c695bc>:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  trainFile['CompetitionDistance'][i] = storeFile['CompetitionDistance'].max()\n","<ipython-input-209-7c7ca1c695bc>:27: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  testFile['CompetitionDistance'][i] = storeFile['CompetitionDistance'][testFile['Store'][i] - 1]\n","<ipython-input-209-7c7ca1c695bc>:29: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  testFile['CompetitionDistance'][i] = storeFile['CompetitionDistance'].max()\n"]}],"metadata":{"id":"NgpB2x79gAHK","outputId":"c0ba5ba7-9f2d-4d64-a3b5-777f2870e124"}},{"cell_type":"code","execution_count":null,"source":["print(trainFile.head())\n","print(testFile.head())"],"outputs":[{"output_type":"stream","name":"stdout","text":["   Store  DayOfWeek       Date  Sales  Open  Promo StateHoliday  \\\n","0      1          5 2015-07-31   5263     1      1            0   \n","1      2          5 2015-07-31   6064     1      1            0   \n","2      3          5 2015-07-31   8314     1      1            0   \n","3      4          5 2015-07-31  13995     1      1            0   \n","4      5          5 2015-07-31   4822     1      1            0   \n","\n","   SchoolHoliday  CompetitionDistance  \n","0           True               1270.0  \n","1           True                570.0  \n","2           True              14130.0  \n","3           True                620.0  \n","4           True              29910.0  \n","   Id  Store  DayOfWeek       Date  Open  Promo StateHoliday  SchoolHoliday  \\\n","0   1      1          4 2015-09-17   1.0      1            0           True   \n","1   2      3          4 2015-09-17   1.0      1            0           True   \n","2   3      7          4 2015-09-17   1.0      1            0           True   \n","3   4      8          4 2015-09-17   1.0      1            0           True   \n","4   5      9          4 2015-09-17   1.0      1            0           True   \n","\n","   CompetitionDistance  \n","0               1270.0  \n","1              14130.0  \n","2              24000.0  \n","3               7520.0  \n","4               2030.0  \n"]}],"metadata":{"id":"2uUo2NWrgAHL","outputId":"6896f4aa-2dce-4ef1-db85-b56cb8044f21"}},{"cell_type":"markdown","source":["A continuacion agregamos algunas columnas de datos que se obtuvieron del archivo Store, a los datos de train y test. Los campos agregados son los siguientes:      \n","- StoreType\n","- Assortment\n","- CompetitionDistance\n","- Promo2\n"],"metadata":{"id":"-VKng1iKydzF"}},{"cell_type":"code","execution_count":null,"source":["#Juntamos información del storeFile a trainFile y a testFile.\n","\n","train = trainFile.merge(storeFile, how='left', left_on='Store', right_on='Store', suffixes=(\"\", \"_y\"))\n","del train['CompetitionDistance_y']\n","del train['CompetitionOpenSinceMonth']\n","del train['CompetitionOpenSinceYear']\n","#del train['Promo2']\n","del train['Promo2SinceWeek']\n","del train['Promo2SinceYear']\n","del train['PromoInterval']\n","del train['CompetitionOpenSince']\n","#print(len(train[train.StoreType.isnull()]))\n","print(train.head())\n","\n","test = testFile.merge(storeFile, how='left', left_on='Store', right_on='Store', suffixes=(\"\", \"_y\"))\n","del test['CompetitionDistance_y']\n","del test['CompetitionOpenSinceMonth']\n","del test['CompetitionOpenSinceYear']\n","#del test['Promo2']\n","del test['Promo2SinceWeek']\n","del test['Promo2SinceYear']\n","del test['PromoInterval']\n","del test['CompetitionOpenSince']\n","#print(len(test[train.StoreType.isnull()]))\n","print(test.head())"],"outputs":[{"output_type":"stream","name":"stdout","text":["   Store  DayOfWeek       Date  Sales  Open  Promo StateHoliday  \\\n","0      1          5 2015-07-31   5263     1      1            0   \n","1      2          5 2015-07-31   6064     1      1            0   \n","2      3          5 2015-07-31   8314     1      1            0   \n","3      4          5 2015-07-31  13995     1      1            0   \n","4      5          5 2015-07-31   4822     1      1            0   \n","\n","   SchoolHoliday  CompetitionDistance StoreType Assortment  Promo2  \n","0           True               1270.0         c          a       0  \n","1           True                570.0         a          a       1  \n","2           True              14130.0         a          a       1  \n","3           True                620.0         c          c       0  \n","4           True              29910.0         a          a       0  \n","   Id  Store  DayOfWeek       Date  Open  Promo StateHoliday  SchoolHoliday  \\\n","0   1      1          4 2015-09-17   1.0      1            0           True   \n","1   2      3          4 2015-09-17   1.0      1            0           True   \n","2   3      7          4 2015-09-17   1.0      1            0           True   \n","3   4      8          4 2015-09-17   1.0      1            0           True   \n","4   5      9          4 2015-09-17   1.0      1            0           True   \n","\n","   CompetitionDistance StoreType Assortment  Promo2  \n","0               1270.0         c          a       0  \n","1              14130.0         a          a       1  \n","2              24000.0         a          c       0  \n","3               7520.0         a          a       0  \n","4               2030.0         a          c       0  \n"]}],"metadata":{"id":"-FpC7rBKgAHM","outputId":"142530a5-a264-4acf-d560-11b93ff8df62"}},{"cell_type":"code","execution_count":null,"source":["train.to_csv('trainPreproc.csv', index=False)\n","test.to_csv('testPreproc.csv', index=False)"],"outputs":[],"metadata":{"id":"-Pe-r4jogAHM"}},{"cell_type":"code","execution_count":2,"source":["train = pd.read_csv('trainPreproc.csv')\n","#print(train.columns)\n","test = pd.read_csv('testPreproc.csv')\n","#print(test.columns)\n","\n","train['StateHoliday'] = train['StateHoliday'].astype(str)\n","test['StateHoliday'] = test['StateHoliday'].astype(str)"],"outputs":[{"output_type":"stream","name":"stderr","text":["/Users/malena/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ryy_AQ1JgAHN","executionInfo":{"status":"ok","timestamp":1636326161169,"user_tz":180,"elapsed":1109,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}},"outputId":"c43e3a9f-a79b-4deb-9267-ff4c69bfd723"}},{"cell_type":"markdown","source":["A continuacion se normalizan las variables continuas empleando la ecuacion:     \n","$\\frac{x_i-\\mu}{\\sigma}$\n","siendo $x_i$ cada uno de los datos, $\\mu$ la media y $\\sigma$ el desvio estandar.\n","Tambien se aplica hot encoder a las variables categoricas.\n"],"metadata":{"id":"WN8PiWGqBThb"}},{"cell_type":"code","execution_count":17,"source":["#Normalizamos las variables continuas y hacemos hot encoder a las variables categóricas.\n","\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from keras.utils import np_utils\n","from sklearn_pandas import DataFrameMapper\n","\n","catColumns = ['Store', 'DayOfWeek', 'StateHoliday', 'StoreType', 'Assortment']\n","contColumns = ['Open', 'CompetitionDistance', 'Promo', 'SchoolHoliday', 'Promo2']\n","\n","# for i in cont:\n","#     xmean = train[i].mean()\n","#     xstd = train[i].std()\n","#     train[i] = (train[i].values - xmean)/xstd\n","\n","# enc = LabelEncoder()\n","# for i in cat:\n","#     enc.fit(train[i])\n","#     train_ = enc.transform(train[i])\n","#     train_ = np_utils.to_categorical(train_)\n","#     print(train_)\n","\n","# print(train.head(train))\n","\n","catEnc = [(i, LabelEncoder()) for i in catColumns]\n","contScal = [([i], StandardScaler()) for i in contColumns] #Se estandarizan las variables continuas.\n","\n","catMapp = DataFrameMapper(catEnc) #Mapea la columna que tienen las variables categóricas (string) en un número de índice (números). [a, b, a, d] = [0, 1, 0, 2]\n","catMapp.fit(train) #Se arma un one hot vector. El fit asigna la cantidad de clases (?)\n","contMapp = DataFrameMapper(contScal)\n","contMapp.fit(train) #Calcula la mdeia y el desvío del dataframe. x' = (x-u)/sigma.\n","\n","train[catColumns] = catMapp.transform(train)\n","test[contColumns] = catMapp.transform(test)\n","train[contColumns] = contMapp.transform(train)\n","test[contColumns] = contMapp.transform(test)\n","print(train[catColumns])\n","print(train[contColumns])"],"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name '_is_pairwise' from 'sklearn.base' (/Users/malena/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-0e0f5ec06275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn_pandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrameMapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcatColumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Store'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DayOfWeek'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'StateHoliday'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'StoreType'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Assortment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn_pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataframe_mapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrameMapper\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeatures_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_features\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumericalTransformer\u001b[0m \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn_pandas/dataframe_mapper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_transformer_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_call_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn_pandas/pipeline.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_name_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtosequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_VisualBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetaestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mavailable_if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m from .utils import (\n\u001b[1;32m     23\u001b[0m     \u001b[0mBunch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_is_pairwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"available_if\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"if_delegate_has_method\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name '_is_pairwise' from 'sklearn.base' (/Users/malena/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py)"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AwogCdK-gAHN","executionInfo":{"status":"ok","timestamp":1636326172599,"user_tz":180,"elapsed":6447,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}},"outputId":"d36b8585-437c-4999-e79f-2d92668da02a"}},{"cell_type":"code","execution_count":6,"source":["#Embeddings.\n","\n","# from tensorflow.keras.models import Model\n","# from tensorflow.keras.optimizers import Adam\n","# from tensorflow.keras.layers import Embedding, Input, Flatten, Dense, Concatenate\n","\n","# catDict = {'Store': 50, 'DayOfWeek': 4, 'StateHoliday': 2, 'StoreType': 2, 'Assortment': 3}\n","\n","# storeIn = Input(shape=(1,), name=\"storeIn\")\n","# storeEmb = Embedding(1115, catDict['Store'], name=\"storeEmb\")(storeIn)\n","# storeFlat = Flatten(name=\"storeFlat\")(storeEmb)\n","# dayofweekIn = Input(shape=(1,), name=\"dayofweekIn\")\n","# dayofweekEmb = Embedding(7, catDict['DayOfWeek'], name=\"dayofweekEmb\")(dayofweekIn)\n","# dayofweekFlat = Flatten(name=\"dayofweekFlat\")(dayofweekEmb)\n","# stateholidayIn = Input(shape=(1,), name=\"stateholidayIn\")\n","# stateholidayEmb = Embedding(4, catDict['StateHoliday'], name=\"stateholidayEmb\")(stateholidayIn)\n","# stateholidayFlat = Flatten(name=\"stateholidayFlat\")(stateholidayEmb)\n","# storetypeIn = Input(shape=(1,), name=\"storetypeIn\")\n","# storetypeEmb = Embedding(4, catDict['StoreType'], name=\"storetypeEmb\")(storetypeIn)\n","# storetypeFlat = Flatten(name=\"storetypeFlat\")(storetypeEmb)\n","# assortmentIn = Input(shape=(1,), name=\"assortmentIn\")\n","# assortmentEmb = Embedding(4, catDict['Assortment'], name=\"assortmentEmb\")(assortmentIn)\n","# assortmentFlat = Flatten(name=\"assortmentFlat\")(assortmentEmb)\n","\n","# openIn = Input(shape=(1,), name=\"openIn\")\n","# openDen = Dense(1, name=\"openDen\", activation = 'linear')(openIn)\n","# competitiondistanceIn = Input(shape=(1,), name=\"competitiondistanceIn\")\n","# competitiondistanceDen = Dense(1, name=\"competitiondistanceDen\", activation = 'linear')(competitiondistanceIn)\n","# promoIn = Input(shape=(1,), name=\"promoIn\")\n","# promoDen = Dense(1, name=\"promoDen\", activation = 'linear')(promoIn)\n","# schoolholidayIn = Input(shape=(1,), name=\"schoolholidayIn\")\n","# schoolholidayDen = Dense(1, name=\"schoolholidayDen\", activation = 'linear')(schoolholidayIn)\n","# promo2In = Input(shape=(1,), name=\"promo2In\")\n","# promo2Den = Dense(1, name=\"promo2Den\", activation = 'linear')(promo2In)\n","\n","# print(train['Store'].value_counts())\n","# print(len(train['Store'].value_counts()))"],"outputs":[],"metadata":{"id":"leK9nM1FgAHO","executionInfo":{"status":"ok","timestamp":1636326213109,"user_tz":180,"elapsed":363,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}}}},{"cell_type":"markdown","source":["A continuacion, mediante embedding reducimos la cantidad de clases de una variable categorica.\n","\n","Dado que tenemos 1115 stores como fuente de datos, lo cual es una enorme cantidad, reducimos este numero y nos quedamos con 50. En cambio, para el resto de los campos de datos nos quedamos con la mitad de la cantidad de datos que tenemos originalmente. Este criterio, conocido como \"la regla del pulgar\", fue obtenida del video del siguiente link:    \n","\n","https://course18.fast.ai/lessonsml1/lesson12.html\n","\n","\n"],"metadata":{"id":"kxWdp7BaCXAD"}},{"cell_type":"code","execution_count":7,"source":["def catEmbeddings(catColumns, catDict):\n","    catOut = []\n","    catIn = []\n","    for i in catColumns:\n","        catIn_ = Input(shape=(1,))\n","        catIn.append(catIn_)\n","        catEmb = Embedding(len(train[i].value_counts()), catDict[i])(catIn_)\n","        catFlat = Flatten()(catEmb)\n","        catOut.append(catFlat)\n","    return catIn, catOut    \n","\n","def contInput(contColumns):\n","    contOut = []\n","    for i in contColumns:\n","        contIn = Input(shape=(1,))\n","        contOut.append(contIn)\n","    return contOut"],"outputs":[],"metadata":{"id":"RkacKRifgAHP","executionInfo":{"status":"ok","timestamp":1636326220252,"user_tz":180,"elapsed":303,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}}}},{"cell_type":"code","execution_count":8,"source":["#Embeddings.\n","\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import Embedding, Input, Flatten, Dense, Concatenate, Activation\n","from tensorflow.keras.regularizers import l2\n","\n","catDict = {'Store': 50, 'DayOfWeek': 4, 'StateHoliday': 2, 'StoreType': 2, 'Assortment': 3}\n","\n","catIn, catOut = catEmbeddings(catColumns, catDict)\n","contIn = contInput(contColumns)\n","\n","merged = Concatenate()(catOut + contIn)"],"outputs":[],"metadata":{"id":"1Xo41dtYgAHP","executionInfo":{"status":"ok","timestamp":1636326225178,"user_tz":180,"elapsed":634,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}}}},{"cell_type":"markdown","source":["## Modelo de procesamiento\n","Realizamos el procesamiento empleando tanto L2 como Dropout y comparamos los resultados obtenidos a partir de cada uno de los casos."],"metadata":{"id":"AzQ_h7-XCmYa"}},{"cell_type":"code","execution_count":9,"source":["def neuralNetwork(merged):\n","    lambdaL2 = 1e-3 #Lambda para la regularización L2.\n","    model = Dense(1000, kernel_initializer=\"uniform\", kernel_regularizer=l2(lambdaL2))(merged)\n","    model = Activation('relu')(model) #'relu' so the cost function has less platous.\n","    model = Dense(1, activation='linear')(model) #'linear' so the output is not categorical.\n","    model = Model(catIn + contIn, [model])\n","    model.compile(optimizer='adam', metrics=['mse'], loss='mse')\n","    #model.compile(optimizer=Adam(lr=0.001), metrics=['mse', rmspe], loss='mse')\n","    return model"],"outputs":[],"metadata":{"id":"m9upUhhlgAHQ","executionInfo":{"status":"ok","timestamp":1636326228302,"user_tz":180,"elapsed":266,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}}}},{"cell_type":"code","execution_count":18,"source":["def neuralNetwork(merged):\n","    lambdaL2 = 1e-3 #Lambda para la regularización L2.\n","    model = Dense(1000, kernel_initializer=\"uniform\", kernel_regularizer=l2(lambdaL2))(merged)\n","    model = Activation('relu')(model) #'relu' so the cost function has less platous.\n","    model = Dropout(0.5)(model)\n","    model = Dense(1, activation='linear')(model) #'linear' so the output is not categorical.\n","    model = Model(catIn + contIn, [model])\n","    model.compile(optimizer='adam', metrics=['mse'], loss='mse')\n","    #model.compile(optimizer=Adam(lr=0.001), metrics=['mse', rmspe], loss='mse')\n","    return model"],"outputs":[],"metadata":{"id":"v76EeBp9f9kI","executionInfo":{"status":"ok","timestamp":1636326569959,"user_tz":180,"elapsed":277,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}}}},{"cell_type":"code","execution_count":null,"source":["# def neuralNetwork(merged):\n","#     lambdaL2 = 1e-3 #Lambda para la regularización L2.\n","#     model = Dense(1000, kernel_initializer=\"uniform\", kernel_regularizer=l2(lambdaL2), activation='relu')(merged) #'relu' so the cost function has less platous.\n","#     model = Dense(1, activation='linear')(model) #'linear' so the output is not categorical.\n","#     return Model(catIn + contIn, [model])"],"outputs":[],"metadata":{"id":"y3J1FbO_gAHQ"}},{"cell_type":"markdown","source":["## Validacion\n","Para esta etapa empleamos la metrica RMSPE, para cada uno de los modelos empleados previamente para el procesamiento ya que asi podremos compararlos."],"metadata":{"id":"HxfZrNkmDpby"}},{"cell_type":"code","execution_count":19,"source":["import datetime\n","\n","train['Date'] = pd.to_datetime(train.Date)\n","valid = train[train.Date >= datetime.datetime(2015, 6, 25)]\n","train = train[train.Date < datetime.datetime(2015, 6, 25)]\n","print(len(train)/(len(train)+len(valid)))\n","print(len(valid)/(len(train)+len(valid)))"],"outputs":[{"output_type":"stream","name":"stdout","text":["1.0\n","0.0\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MxX3iNG3gAHR","executionInfo":{"status":"ok","timestamp":1636326585157,"user_tz":180,"elapsed":303,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}},"outputId":"313b58f9-b378-413b-e29f-6bb17629dc5d"}},{"cell_type":"code","execution_count":20,"source":["def rmspeMetric(valid, predY):\n","    rmspe = 0\n","    for i in range(len(predY)):\n","        if(valid['Sales'][i] != 0):\n","            rmspe = rmspe + ((valid['Sales'][i] - predY[i])/valid['Sales'][i])**2\n","    rmspe = np.sqrt(rmspe/len(predY))\n","    return rmspe\n","# def rmspeMetric(validY, predY):\n","#     return np.sqrt((((validY - predY)/validY)**2).mean())"],"outputs":[],"metadata":{"id":"yFZemUlngAHR","executionInfo":{"status":"ok","timestamp":1636326587758,"user_tz":180,"elapsed":274,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}}}},{"cell_type":"code","execution_count":21,"source":["columns = catColumns + contColumns\n","trainX = np.hsplit(train[columns].values, len(columns))\n","validX = np.hsplit(valid[columns].values, len(columns))\n","testX = np.hsplit(test[columns].values, len(columns))"],"outputs":[],"metadata":{"id":"oGKVQwybgAHR","executionInfo":{"status":"ok","timestamp":1636326589285,"user_tz":180,"elapsed":290,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}}}},{"cell_type":"code","execution_count":24,"source":["#print(train.groupby('Store').mean()['Sales'])\n","trainY = (train['Sales'].values - train.groupby('Store').mean()['Sales'][train['Store']].values)\n","trainYmax = trainY.max()\n","trainY = trainY/trainYmax\n","#trainY = np.hsplit(trainY, trainY.shape[1])\n","print(trainY)\n","validY = (valid['Sales'].values - valid.groupby('Store').mean()['Sales'][valid['Store']].values)\n","validYmax = validY.max() # COMENTO ESTOOOO\n","validY = validY/validYmax\n","#validY = np.hsplit(validY, validY.shape[1])\n","print(validY)"],"outputs":[{"output_type":"stream","name":"stdout","text":["[-0.01835703  0.0210813  -0.00853301 ... -0.16756264 -0.52005182\n"," -0.15797597]\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-319fa0205ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvalidY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Store'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Store'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mvalidYmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# COMENTO ESTOOOO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mvalidY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidY\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvalidYmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#validY = np.hsplit(validY, validY.shape[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     37\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     38\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n","\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"kmwX2T8MgAHS","executionInfo":{"status":"error","timestamp":1636327364079,"user_tz":180,"elapsed":277,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}},"outputId":"56c5005f-10e0-4402-f9dd-865f68919ba7"}},{"cell_type":"code","execution_count":25,"source":["model = neuralNetwork(merged)\n","model.fit(trainX, trainY, validation_data=(validX, validY),  epochs=20, batch_size=256, verbose=2)\n","#model.fit(trainX, trainY, epochs=20, batch_size=256, verbose=2)"],"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-36baa947d8b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#model.fit(trainX, trainY, epochs=20, batch_size=256, verbose=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-9a718fb6d98e>\u001b[0m in \u001b[0;36mneuralNetwork\u001b[0;34m(merged)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uniform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdaL2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#'relu' so the cost function has less platous.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#'linear' so the output is not categorical.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatIn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcontIn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Dropout' is not defined"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"Qy44bHxhgAHS","executionInfo":{"status":"error","timestamp":1636327389030,"user_tz":180,"elapsed":297,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}},"outputId":"e90f2f4b-39b6-42f0-ff7d-d8e4375c7dde"}},{"cell_type":"code","execution_count":26,"source":["loss, acc = model.evaluate(trainX, trainY)\n","print(acc)\n","\n","loss, acc = model.evaluate(validX, validY)\n","print(acc)"],"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-16dc96a5aaf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"-rJ30Q_tgAHS","executionInfo":{"status":"error","timestamp":1636327405838,"user_tz":180,"elapsed":404,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}},"outputId":"1dbca092-f000-479a-9582-6850debe7552"}},{"cell_type":"code","execution_count":1,"source":["predY = model.predict(validX, verbose = 1)[:,0]*trainYmax\n","rmspe = rmspeMetric(valid, predY)\n","print(rmspe)\n","\n","# predY = model.predict(testX, verbose = 1)[:,0]*trainYmax\n","# rmspe = rmspeMetric(test, predY)\n","# print(rmspe)"],"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-804736b3a910>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrainYmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrmspe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrmspeMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmspe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# predY = model.predict(testX, verbose = 1)[:,0]*trainYmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"Y2sk8uy_i07H","executionInfo":{"status":"error","timestamp":1636324620445,"user_tz":180,"elapsed":14,"user":{"displayName":"Malena Müller","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09250792217728645100"}},"outputId":"e44192c2-0aa0-4bfb-949a-febb7ec307e8"}}]}